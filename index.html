<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ECG Analysis | AI Detector</title>
    <!-- 1. Load Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- 2. Load TensorFlow.js for in-browser deep learning -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    
    <style>
        /* Custom font for a more modern feel */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap');
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0f172a; /* Slate 900 */
        }

        /* --- Creative Heartbeat Animation --- */
        /* This will be our "loading" and "processing" indicator */
        .heartbeat-loader {
            width: 100px;
            height: 100px;
            position: relative;
            display: flex;
            align-items: center;
            justify-content: center;
            animation: pulse 1s infinite;
        }
        .heartbeat-svg {
            fill: #22d3ee; /* Cyan 400 */
            stroke: #06b6d4; /* Cyan 600 */
            stroke-width: 2;
        }
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        /* --- Fade-in animation for results --- */
        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }
        .animate-fadeIn {
            animation: fadeIn 0.5s ease-out forwards;
        }

        /* --- Custom file input button --- */
        input[type="file"] {
            display: none;
        }
        .file-upload-label {
            cursor: pointer;
            transition: all 0.3s ease;
        }
        .file-upload-label:hover {
            transform: scale(1.05);
            box-shadow: 0 0 25px rgba(34, 211, 238, 0.3);
        }
    </style>
</head>
<body class="bg-slate-900 text-white min-h-screen flex items-center justify-center p-4">

    <div class="max-w-xl w-full bg-slate-800 rounded-2xl shadow-2xl p-6 md:p-10 border border-slate-700">
        
        <!-- Header Section -->
        <div class="text-center mb-6">
            <h1 class="text-3xl font-bold text-cyan-400">Cardiovascular Disease Detector</h1>
            <p class="text-slate-400 mt-2">Upload an ECG graph to analyze it with our ResNet50 AI model.</p>
        </div>

        <!-- 1. Upload Section -->
        <div id="upload-section" class="text-center">
            <label for="file-upload" class="file-upload-label inline-block bg-cyan-500 hover:bg-cyan-600 text-white font-bold py-3 px-6 rounded-lg shadow-lg">
                Upload Your ECG Image
            </label>
            <input id="file-upload" type="file" accept="image/*">
            <p id="file-name" class="text-slate-500 text-sm mt-3"></p>
        </div>

        <!-- 2. Image Preview Section -->
        <div id="image-preview-container" class="hidden mt-6 text-center">
            <img id="image-preview" src="#" alt="Your ECG Upload" class="max-w-full h-auto mx-auto rounded-lg shadow-md border-2 border-slate-700 max-h-64"/>
            <button id="analyze-button" class="mt-6 w-full bg-green-500 hover:bg-green-600 text-white font-bold py-3 px-6 rounded-lg shadow-lg transition duration-300 ease-in-out transform hover:scale-105">
                Analyze Image
            </button>
        </div>

        <!-- 3. Processing/Loading Section (Animated Heartbeat) -->
        <div id="processing-section" class="hidden text-center py-10">
            <div class="heartbeat-loader mx-auto">
                <svg class="heartbeat-svg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M12 21.35l-1.45-1.32C5.4 15.36 2 12.28 2 8.5 2 5.42 4.42 3 7.5 3c1.74 0 3.41.81 4.5 2.09C13.09 3.81 14.76 3 16.5 3 19.58 3 22 5.42 22 8.5c0 3.78-3.4 6.86-8.55 11.54L12 21.35z"/></svg>
            </div>
            <p class="text-cyan-400 text-lg font-medium mt-4">Analyzing... Please wait.</p>
            <p class="text-slate-400 text-sm">The AI is scanning your ECG image.</p>
        </div>

        <!-- 4. Result Section -->
        <div id="result-section" class="hidden text-center mt-8 animate-fadeIn">
            <h2 class="text-2xl font-bold text-slate-100 mb-2">Analysis Complete</h2>
            <p class="text-lg text-slate-300">The model has identified the following:</p>
            
            <div id="result-box" class="mt-4 bg-slate-900 border-2 rounded-lg p-6 w-full max-w-sm mx-auto">
                <p class="text-sm font-medium text-cyan-400">PREDICTION</p>
                <p id="result-text" class="text-4xl font-bold text-white my-2">Normal</p>
                <p class="text-sm font-medium text-slate-400">CONFIDENCE</p>
                <p id="confidence-text" class="text-2xl font-semibold text-green-400">98.7%</p>
            </div>
        </div>

    </div>

    <script>
        // --- Get DOM Elements ---
        const fileUpload = document.getElementById('file-upload');
        const fileName = document.getElementById('file-name');
        const imagePreviewContainer = document.getElementById('image-preview-container');
        const imagePreview = document.getElementById('image-preview');
        const analyzeButton = document.getElementById('analyze-button');
        
        const uploadSection = document.getElementById('upload-section');
        const processingSection = document.getElementById('processing-section');
        const resultSection = document.getElementById('result-section');
        
        const resultText = document.getElementById('result-text');
        const confidenceText = document.getElementById('confidence-text');
        const resultBox = document.getElementById('result-box');

        // --- Model and Configuration ---

        // !!! STEP 1: MUST UPDATE THIS URL !!!
        // This is the URL to your converted model.json file (from your Gist).
        const MODEL_URL = 'https://cyberwiser21.github.io/ECG/model.json'; // This is CORRECT; // e.g., 'https://gist.githubusercontent.com/.../model.json'

        // !!! STEP 2: MUST UPDATE THESE CLASSES !!!
        // The class names must be in the *exact* same order as your training data.
        const CLASS_NAMES = ['F','M','N','Q','S','V'];
        
        const IMAGE_SIZE = 224; // Must match your model's input size (224x224)

        let model;

        // --- Main Functions ---

        /**
         * Loads the converted TensorFlow.js model from the URL.
         */
        async function loadModel() {
            console.log("Loading model...");
            try {
                model = await tf.loadLayersModel(MODEL_URL);
                console.log("Model loaded successfully!");
            } catch (err) {
                console.error("Failed to load model", err);
                alert("Error: Could not load the AI model. Please check the MODEL_URL in the script.");
            }
        }

        /**
         * Handles the file upload event.
         */
        function handleFileSelect(event) {
            const file = event.target.files[0];
            if (file) {
                fileName.textContent = file.name;
                
                // Use FileReader to display the image preview
                const reader = new FileReader();
                reader.onload = (e) => {
                    imagePreview.src = e.target.result;
                    imagePreviewContainer.classList.remove('hidden');
                    // Hide the initial upload button, show the preview and analyze button
                    uploadSection.classList.add('hidden');
                    resultSection.classList.add('hidden'); // Hide old results
                };
                reader.readAsDataURL(file);
            }
        }

        /**
         * Runs the analysis by preprocessing the image and calling the model.
         */
        async function runAnalysis() {
            if (!model) {
                alert("Model is not loaded yet. Please wait.");
                return;
            }

            // 1. Show processing animation, hide other sections
            processingSection.classList.remove('hidden');
            imagePreviewContainer.classList.add('hidden');
            resultSection.classList.add('hidden');

            try {
                // 2. Preprocess the image
                const tensor = preprocessImage(imagePreview);

                // 3. Run prediction
                const predictions = await model.predict(tensor).data();
                
                // 4. Post-process the results
                const { className, confidence } = processResults(predictions);

                // 5. Display the results
                displayResults(className, confidence);

            } catch (err) {
                console.error("Error during analysis:", err);
                alert("An error occurred during analysis. Please try again.");
                // Reset UI
                processingSection.classList.add('hidden');
                imagePreviewContainer.classList.remove('hidden');
            }
        }

        /**
         * Converts the HTML <img> element to a tensor that the model expects.
         * This MUST match your Python preprocessing!
         */
        function preprocessImage(imgElement) {
            // tf.browser.fromPixels gets the image data
            // .resizeBilinear scales it to 224x224
            // .div(255.0) normalizes the pixels (just like rescale=1./255)
            // .expandDims(0) adds the batch dimension (1, 224, 224, 3)
            return tf.tidy(() => {
                const tensor = tf.browser.fromPixels(imgElement)
                    .resizeBilinear([224,224])
                    .toFloat()
                    .div(255.0)
                    .expandDims(0);
                return tensor;
            });
        }

        /**
         * Finds the highest-confidence class from the model's output.
         */
        function processResults(predictions) {
            let maxIndex = 0;
            let maxConfidence = 0;

            for (let i = 0; i < predictions.length; i++) {
                if (predictions[i] > maxConfidence) {
                    maxConfidence = predictions[i];
                    maxIndex = i;
                }
            }
            const className = CLASS_NAMES[maxIndex];
            const confidence = maxConfidence * 100;
            return { className, confidence };
        }

        /**
         * Updates the UI to show the final prediction.
         */
        function displayResults(className, confidence) {
            // Hide processing, show results
            processingSection.classList.add('hidden');
            resultSection.classList.remove('hidden');
            
            // Re-show the upload button for the next analysis
            uploadSection.classList.remove('hidden');
            fileName.textContent = 'Upload a new image...';
            fileUpload.value = ''; // Clear the file input

            // Set result text and styling
            resultText.textContent = className;
            confidenceText.textContent = `${confidence.toFixed(1)}%`;

            // Make the result box color-coded (example)
            // You can customize this logic
            if (className.toLowerCase() === 'normal') {
                resultBox.style.borderColor = '#22c55e'; // Green
                confidenceText.style.color = '#22c55e';
            } else {
                resultBox.style.borderColor = '#ef4444'; // Red
                confidenceText.style.color = '#ef4444';
            }
        }

        // --- Event Listeners ---
        fileUpload.addEventListener('change', handleFileSelect);
        analyzeButton.addEventListener('click', runAnalysis);
        
        // Load the model as soon as the page loads
        window.onload = loadModel;

    </script>
</body>
</html>